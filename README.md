# ML-challenge-23

original link to kaggle notebook https://www.kaggle.com/code/dhruvansh26/keyword-tokenization

involves abstraction of text data using nltk keyword extractor(rake), then fed into bert tokenizer. Further fed into distilbert model using regression, to predict product length(target)
parameters used for training- mape
normalisation using standardscaler
